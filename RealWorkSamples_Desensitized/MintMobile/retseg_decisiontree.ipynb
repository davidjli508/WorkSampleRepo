{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Constants & Functions\n",
    "XGB_FEATCOLS = 'clust'\n",
    "\n",
    "NUM_CLUSTS = 13\n",
    "\n",
    "DTC_PARAM_GRID = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 5, 10],\n",
    "    'max_features': [None, 'sqrt', 'log2'],\n",
    "    'max_leaf_nodes': [None, 10, 20, 30, 40, 50],\n",
    "    'min_impurity_decrease': [0.0, 0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "XGB_DEFAULT_PARAMS = {\n",
    "    'criterion': ['gini'],\n",
    "    'splitter': ['best'],\n",
    "    'max_depth': [None],\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [1],\n",
    "    'max_features': [None],\n",
    "    'max_leaf_nodes': [None],\n",
    "    'min_impurity_decrease': [0.0]\n",
    "}\n",
    "\n",
    "XGB_JUN_MDL_PARAMS = {\n",
    "    'criterion': ['gini'],\n",
    "    'splitter': ['random'],\n",
    "    'max_depth': [None],\n",
    "    'min_samples_split': [2],\n",
    "    'min_samples_leaf': [1],\n",
    "    'max_features': ['sqrt'],\n",
    "    'max_leaf_nodes': [None],\n",
    "    'min_impurity_decrease': [0.0]\n",
    "}\n",
    "\n",
    "CORR_COL_ORDER = ['ACTIVATING_SALE_GROUP_NAME_grouped_Direct EComm',\n",
    "    'ACTIVATING_SALE_GROUP_NAME_grouped_National Retail', \n",
    "    'PROMO_GROUPED_Deflation', \n",
    "    #'PROMO_GROUPED_Device bundle', \n",
    "    'PROMO_GROUPED_No Promo',\n",
    "    'GSMA_OPERATING_SYSTEM_grouped_iOS',\n",
    "    'PLAN_CYCLE_NUM_grouped', \n",
    "    'FAILED_PAYMENT_GROUPED',\n",
    "    'MEMBER_OF_ACTIVE_FAMILY_FLAG', \n",
    "    #'ACS_HP_PROP',\n",
    "    #'ACS_NOT_HP_ASIAN_ALONE_PROP',\n",
    "    #'ACS_NOT_HP_AFRICAN_AMERICAN_ALONE_PROP',\n",
    "    #'ACS_NOT_HP_WHITE_ALONE_PROP', \n",
    "    #'ACS_PROP_WORKERS_OVER_16',\n",
    "    #'ACS_AGE_MEDIAN', \n",
    "    #'ACS_INCOME_MEDIAN', \n",
    "    #'ACS_APPROX_COMMUTE_MEDIAN', \n",
    "    #'NO_SCHOOL_PROP',\n",
    "    #'ANY_DEGREE_PROP',\n",
    "    #'SINGLE_MOM_PROP',\n",
    "    #'NEVER_MARRIED_PROP',\n",
    "    #'HH_WO_INT_ACCESS_PROP',\n",
    "    #'OCCUP_HOUS_UNIT_WO_CAR_PROP',\n",
    "    'UPGRADE_DOWNGRADE_DATA_FLAG', \n",
    "    'UPGRADE_DOWNGRADE_DURATION_FLAG',\n",
    "    'SUB_ESIM_FLAG', \n",
    "    #'HAD_ISSUES_PORTING_IN', \n",
    "    'EVER_LOGGED_INTO_APP_FLAG',\n",
    "    'LTE_BAND_71',\n",
    "    #'contacted_care_last7d', \n",
    "    'contacted_care_last30d',\n",
    "    'SERVICE_ISSUE_NOTE_FLAG',\n",
    "    #'SIM_REPLACEMENT_NOTE_FLAG', \n",
    "    #'PAYMENT_NOTE_FLAG',\n",
    "    'EXPECTED_CLV_PS',\n",
    "    'PORTIN_ISSUE_DESC_NoIssues',\n",
    "    'PORTIN_ISSUE_DESC_NonPortin',\n",
    "    'L1_CLUST_0',\n",
    "    #'L1_CLUST_1',\n",
    "    'L1_CLUST_2',\n",
    "    'L1_CLUST_3',\n",
    "    'L1_CLUST_4',\n",
    "    'L1_CLUST_5',\n",
    "    'L1_CLUST_6']\n",
    "\n",
    "JUN_OUTPUT_FOLDER = \"C:/Users/davidl/OneDrive - ULTRA MOBILE/Desktop/dli_code/RetSeg/output/114/\"\n",
    "JUN_DF_NAME = \"jun_hclust13_10p_mdl_output.csv\"\n",
    "\n",
    "MDL_EXPORT_NAME = \"jun_hclust13_10p_mdl.pkl\"\n",
    "\n",
    "def dtcModelPrep(df, paramGrid, search_yn):\n",
    "    X = df.drop(columns=XGB_FEATCOLS)\n",
    "    y = df[XGB_FEATCOLS]\n",
    "    # Split into Train & Test Sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Do a Hyperparameter Search if needed\n",
    "    if search_yn.upper() == \"Y\":\n",
    "\n",
    "        print(\"Creating DecisionTreeClassifier..\")\n",
    "        # Initialize the Decision Tree classifier\n",
    "        dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "        print(\"Creating RandomSearchCV..\")\n",
    "        # Initialize RandomizedSearchCV\n",
    "        random_search = RandomizedSearchCV(estimator=dt_clf, param_distributions=paramGrid, \n",
    "                                           n_iter=100, scoring='accuracy', cv=3, verbose=2, n_jobs=1, random_state=42)\n",
    "\n",
    "        print(\"Fitting RandomSearchCV..\")\n",
    "        # Fit the model\n",
    "        random_search.fit(X_train, y_train)\n",
    "    \n",
    "        # Print the best parameters and best score\n",
    "        print(f\"Best Parameters: {random_search.best_params_}\")\n",
    "        print(f\"Best Score: {random_search.best_score_}\")\n",
    "        return X_train, X_test, y_train, y_test, random_search.best_params_, random_search.best_score_\n",
    "    # Else Bypass HP Search\n",
    "    else:\n",
    "        return X_train, X_test, y_train, y_test, XGB_DEFAULT_PARAMS\n",
    "\n",
    "def create_eval_dtcModel(X_train, X_test, y_train, y_test, param_grid, create_pickle):\n",
    "    # Set parameters\n",
    "    params = {\n",
    "        'criterion': param_grid['criterion'],\n",
    "        'splitter': param_grid['splitter'],\n",
    "        'max_depth': param_grid['max_depth'],\n",
    "        'min_samples_split': param_grid['min_samples_split'],\n",
    "        'min_samples_leaf': param_grid['min_samples_leaf'],\n",
    "        'max_features': param_grid['max_features'],\n",
    "        'max_leaf_nodes': param_grid['max_leaf_nodes'],\n",
    "        'min_impurity_decrease': param_grid['min_impurity_decrease']\n",
    "    }\n",
    "\n",
    "    print(\"Training Decision Tree Model..\")\n",
    "    # Train the model\n",
    "    dt_clf = DecisionTreeClassifier(**params)\n",
    "    dt_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Print the decision tree rules\n",
    "    tree_rules = export_text(dt_clf, feature_names=list(X_train.columns))\n",
    "    print(\"Decision Tree Rules:\\n\")\n",
    "    print(tree_rules)\n",
    "    \n",
    "    # Save the decision tree rules to a text file\n",
    "    with open('decision_tree_rules.txt', 'w') as f:\n",
    "        f.write(tree_rules)\n",
    "\n",
    "    # Visualize the decision tree and save as a high-resolution JPG file\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plot_tree(dt_clf, max_depth = 5, feature_names=list(X_train.columns), class_names=True, filled=True)\n",
    "    plt.savefig('decision_tree_visual.jpg', dpi=1200)  # Increase dpi for higher resolution\n",
    "    plt.close()\n",
    "\n",
    "    # Save the model to a file\n",
    "    if create_pickle[0].upper() == \"Y\":\n",
    "        with open(create_pickle[1], 'wb') as f:\n",
    "            pickle.dump(dt_clf, f)\n",
    "\n",
    "    print(\"Predicting Using Decision Tree Model..\")\n",
    "    # Make predictions\n",
    "    preds = dt_clf.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    precision = precision_score(y_test, preds, average='macro')\n",
    "    recall = recall_score(y_test, preds, average='macro')\n",
    "    f1 = f1_score(y_test, preds, average='macro')\n",
    "\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {f1}\")\n",
    "    \n",
    "    # Return Model Object\n",
    "    return dt_clf\n",
    "    \n",
    "\n",
    "def predNewData(dt_pkl, pred_df, create_pred_file):\n",
    "    # IMPORTANT: Assumes data is already scaled\n",
    "\n",
    "    # If dt_pkl is a direct model object\n",
    "    if hasattr(dt_pkl, 'predict'):\n",
    "        loaded_model = dt_pkl\n",
    "    # If dt_pkl is the string name of the path to the pickled model\n",
    "    elif isinstance(dt_pkl, str):\n",
    "        with open(dt_pkl, 'rb') as f:\n",
    "            loaded_model = pickle.load(f)\n",
    "    else:\n",
    "        print(\"ERROR: MODEL OBJECT UNKNOWN\")\n",
    "        return 0\n",
    "\n",
    "    print(\"Predicting On Given DF..\")\n",
    "    # Make predictions\n",
    "    new_preds = loaded_model.predict(pred_df)\n",
    "    \n",
    "    # Add predictions to the DataFrame\n",
    "    pred_df['pred_clust'] = new_preds\n",
    "\n",
    "    # Save the predicted DataFrame to a file if requested\n",
    "    if create_pred_file[0].upper() == \"Y\":\n",
    "        pred_df.to_csv(create_pred_file[1], index=False)\n",
    "    \n",
    "    return pred_df\n",
    "\n",
    "def getFeatureImp(dt_pkl, txt_file_name):\n",
    "    # If dt_pkl is a direct model object\n",
    "    if hasattr(dt_pkl, 'predict'):\n",
    "        loaded_model = dt_pkl\n",
    "    # If dt_pkl is the string name of the path to the pickled model\n",
    "    elif isinstance(dt_pkl, str):\n",
    "        with open(dt_pkl, 'rb') as f:\n",
    "            loaded_model = pickle.load(f)\n",
    "    else:\n",
    "        print(\"ERROR: MODEL OBJECT UNKNOWN\")\n",
    "        return 0\n",
    "    \n",
    "    importances = loaded_model.feature_importances_\n",
    "    \n",
    "    # If you have feature names, you can pair them with their importances\n",
    "    feature_importances = zip(CORR_COL_ORDER, importances)\n",
    "    \n",
    "    # Sort the features by importance\n",
    "    sorted_feature_importances = sorted(feature_importances, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Print the feature importances\n",
    "    for feature, importance in sorted_feature_importances:\n",
    "        print(f\"{feature}: {importance:.4f}\")\n",
    "        \n",
    "    # Writing to a .txt file\n",
    "    with open(txt_file_name, 'w') as f:\n",
    "        for feature, importance in sorted_feature_importances:\n",
    "            f.write(f\"{feature}: {importance:.4f}\\n\")\n",
    "    \n",
    "    return importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(JUN_OUTPUT_FOLDER + JUN_DF_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = \"Unnamed: 0\", axis = 1, inplace = True)\n",
    "df.drop(columns = \"silhouette_score\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step1 = dtcModelPrep(df, DTC_PARAM_GRID, search_yn = \"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step2 = create_eval_dtcModel(step1[0], step1[1], step1[2], step1[3], step1[4], create_pickle = [\"Y\", MDL_EXPORT_NAME])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step3 = predNewData(\"C:/Users/davidl/OneDrive - ULTRA MOBILE/Desktop/dli_code/RetSeg/\" + MDL_EXPORT_NAME, step1[1], [\"n\", \"pred_test.csv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step4 = getFeatureImp(\"C:/Users/davidl/OneDrive - ULTRA MOBILE/Desktop/dli_code/RetSeg/\" + MDL_EXPORT_NAME, \"feature_importance_written.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "\n",
    "Interpreting the feature importance output from a DecisionTreeClassifier can provide valuable insights into which features are most influential in making predictions. Here's how you can interpret the results:\n",
    "\n",
    "Feature Importance Values: Each feature is assigned an importance score between 0 and 1. These scores represent the relative importance of each feature in the decision-making process of the tree. A higher score indicates a more important feature.\n",
    "\n",
    "Sum of Importances: The sum of all feature importance scores is 1. This means the importance scores are normalized, making it easier to compare the relative importance of different features.\n",
    "\n",
    "Ranking Features: By sorting the features based on their importance scores, you can identify which features have the most significant impact on the model's predictions. Features with higher importance scores contribute more to the decision-making process.\n",
    "\n",
    "Understanding the Model: Knowing which features are most important can help you understand how the model is making decisions. For example, if a particular feature has a high importance score, it means that feature is frequently used in the decision nodes of the tree.\n",
    "\n",
    "Feature Selection: Feature importance can also be used for feature selection. You might choose to keep only the most important features and discard less important ones to simplify the model and potentially improve its performance.\n",
    "\n",
    "In the Example Above, L1_CLUST_6 contributes to 17% of the model's decisions, PORTIN_ISSUE_DESC_NonPortin contributes to 12% of the model's decisions, EXPECTED_CLV_PS contributes to 0.7% of the model's decisions, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = step3\n",
    "newdf[\"act_clust\"] = step1[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame with \"pred_clust\" and \"act_clust\" columns\n",
    "def count_mismatched_rows(df):\n",
    "    # Count the number of rows where \"pred_clust\" and \"act_clust\" don't match\n",
    "    mismatched_rows = df[df['pred_clust'] != df['act_clust']].shape[0]\n",
    "    return mismatched_rows\n",
    "mismatched_count = count_mismatched_rows(newdf)\n",
    "print(f\"Number of rows where 'pred_clust' and 'act_clust' don't match: {mismatched_count}\")\n",
    "print(newdf.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
